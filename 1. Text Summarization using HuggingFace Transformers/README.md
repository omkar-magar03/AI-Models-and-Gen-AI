# Text Summarization using HuggingFace Transformers

![Python](https://img.shields.io/badge/Python-3.x-blue.svg)

![Libraries](https://img.shields.io/badge/Libraries-LangChain%2C%20Transformers-orange.svg)

## ðŸ“ Overview

This project provides a practical guide to performing text summarization using a pre-trained model from the [HuggingFace Transformers](https://huggingface.co/docs/transformers/index) library. It demonstrates how to load the `facebook/bart-large-cnn` model, process user-provided text, and generate a concise summary. The notebook also dives into fine-tuning the model's output by dynamically adjusting parameters to handle texts of varying lengths, ensuring the summary is both relevant and appropriately sized.

## âœ¨ Features

* **Environment Setup Guide:** Includes clear, step-by-step instructions for setting up the environment in Google Colab, including how to log in to the Hugging Face CLI.
* **Token Calculation:** Calculates and displays the number of input and output tokens handled by the model for transparency and analysis.
* **Pre-trained Model Integration:** Utilizes the powerful `facebook/bart-large-cnn` model for high-quality text summarization.
* **Dynamic Summary Length:** Implements a method to adjust the summary's `max_length` based on the input text's token count, making it effective for both long and short articles.
* **Parameter Fine-Tuning:** Shows how to control summary generation with parameters like `max_length`, `min_length`, and `do_sample` for more deterministic and customized outputs.
* **GPU Acceleration:** Contains a check to confirm GPU availability via `torch.cuda.is_available()` to accelerate model inference.


## ðŸ› ï¸ Installation

1. Install the required dependencies in your Python environment:

```bash
pip install transformers langchain langchain_huggingface
```

2. (Optional) For access to gated models or to upload your own, log in to your Hugging Face account via the command line. The notebook provides instructions on how to do this in a Google Colab environment.

```bash
huggingface-cli login
```


> The notebook was developed in Google Colab, but it can be run locally. A GPU is recommended for faster processing.

## ðŸš€ Usage

1. **Clone or download** this repository and open the notebook: `testing_summarization_model.ipynb`
2. **Ensure you have a Hugging Face account \& access token** for authenticated access to some models. (Instructions provided in the notebook)
3. **Run all cells** to initialize dependencies and environment.
4. **Enter the text** you wish to summarize when prompted.
5. **View the summary output** generated by the model.
6. **Experiment further** by trying different input lengths or tuning summarization parameters in the notebook.

### Example

```
Please enter the text you would like to summarize: 
Cyberpunk 2077 is coming to macOS later this week, after it was originally set to debut in early 2025...

Output Summary:-
Cyberpunk 2077: Ultimate Edition will be available for Apple silicon devices for the first time on July 17th. CD Projekt Red has optimized the game for a variety of Mac hardware, from the early M1 models up to the latest M4 chip family. Only some M1 and M2 Macs are supported, though â€” youâ€™ll need a Mac with 16GB or more of unified memory.
```


## ðŸ§© Model Used

- **Summarization:** [`facebook/bart-large-cnn`](https://huggingface.co/facebook/bart-large-cnn)


## ðŸ“¦ Dependencies

- `Python 3.x`
- `transformers`
- `langchain`
- `langchain_huggingface`
- `torch` (for GPU support)

> **Note:** Refer to the notebook for additional setup instructions regarding Hugging Face token authentication.

